{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from data_generator.csv_data_processor import CSVDataProcessor\n",
    "from utils.util_funcs import get_row_count, display_df\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import to_date, col, floor, datediff, current_date, lower, lit, array, rand, collect_list, size, array, floor\n",
    "\n",
    "\n",
    "\n",
    "spark = SparkSession.builder.appName(\"ETL\").getOrCreate()\n",
    "\n",
    "csv_reader = CSVDataProcessor(spark, \"data/healthcare_dataset.csv\")\n",
    "\n",
    "# Read the CSV file\n",
    "df = csv_reader.run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import lit, to_date, datediff, current_date, floor, date_add\n",
    "\n",
    "\n",
    "start_date = to_date(lit(\"1935-01-01\"))  # Start of the date range\n",
    "range_days = 365 * 90  # Number of days in the range  365 * years\n",
    "\n",
    "df = (df.withColumn(\"RandomDays\", (rand() * range_days).cast(\"int\"))\n",
    "        .withColumn(\"DOB\", date_add(start_date, \"RandomDays\")).drop(\"age\") \n",
    "       .withColumn(\"Age\", floor(datediff(current_date(), col(\"DOB\")) / 365)))\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "62f17c7d47c49e7e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c719587b71c56094"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from constants.admission_types_tests_dataset import admission_mapping, admission_tests\n",
    "# Flatten the mapping and create a DataFrame\n",
    "flattened = [\n",
    "    (top_level, sub_level, stay_type, admission_tests.get(sub_level, [\"No tests\"]))\n",
    "    for top_level, sub_level_dict in admission_mapping.items()\n",
    "    for sub_level, stay_types in sub_level_dict.items()\n",
    "    for stay_type in stay_types\n",
    "]\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d463e373907bf09e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "mapping_df = spark.createDataFrame(flattened, [\"top_level_admission\", \"sub_level_admission\", \"stay_type\", \"possible_tests\"])\n",
    "\n",
    "display_df(mapping_df)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e1dc302cbd5cd49e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# create joining column to mapping_df\n",
    "admission_types = list(admission_mapping.keys())\n",
    "\n",
    "print(admission_types)\n",
    "\n",
    "keys_array = array([lit(key) for key in admission_types])\n",
    "\n",
    "df = df.withColumn(\"top_level_admission\", keys_array[floor(rand() * len(admission_types))]).drop(\"admission_type\")\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b51112bb4b4cff7a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "46c97813ffa7c0c0"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "# Define constants and conditions\n",
    "female_only = ['maternity', 'obstetrics']\n",
    "is_female = lower(col('gender')) == 'female'\n",
    "is_pediatric = col(\"Age\") < 18\n",
    "is_geriatric = (col(\"Age\") >= 65) & (col(\"sub_level_admission\") == \"geriatrics\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5ee1a26cd79cbce"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import concat, when\n",
    "from data_generator.constants import ColConstants\n",
    "\n",
    "df = (df.withColumn(\"is_female\", is_female)\n",
    "        .withColumn(\"is_pediatric\", is_pediatric)\n",
    "        .withColumn(\"top_level_admission\", \n",
    "                    when(col(\"is_pediatric\"), \n",
    "                            concat(lit(ColConstants.peds), \n",
    "                                   col(\"top_level_admission\")\n",
    "                                   )\n",
    "                            ).otherwise(col(\"top_level_admission\"))\n",
    "                    )\n",
    "      )"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "621b426ea41d5871"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.show(n=8000)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "687079f7fa44cf1e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StringType\n",
    "\n",
    "df = df.select([col(c).cast(StringType()).alias(c) for c in df.columns])\n",
    "df.write.csv('./temp_data/temp.csv', mode = 'overwrite', header=True)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "40d057b30f38c3b0"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "d73ef43883d77dd2"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
